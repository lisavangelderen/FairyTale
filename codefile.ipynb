{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the analysis part of the project, a little preprocessing has to be done. To start, we create a list with all the stories in it. Next we take apart each token to save only the lemmatized token, and remove unnecessary tokens (such as \"/n\" or punctuation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# appends to file_list all files inside the particular folder given below that end with \".txt\"\n",
    "file_list = []\n",
    "for file_name in glob.iglob(\"data/**/*.txt\", recursive=True):\n",
    "    file_list.append(file_name)\n",
    "\n",
    "# appends each line of each story to story_list\n",
    "story_list = []\n",
    "for file in file_list:\n",
    "    with open(file, \"r\", encoding='UTF-8') as story:\n",
    "        lines = story.readlines()\n",
    "        story_list.append(lines)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/cluster083/253635663-THE-FARMYARD-COCK-AND-THE-WEATHERCOCK-H-C-Andersen.txt',\n",
       " 'data/cluster083/384500260-THE-BUTTERFLY-H-C-Andersen.txt',\n",
       " 'data/cluster083/798449202-The-Three-Languages-Brothers-Grimm.txt',\n",
       " 'data/cluster083/477325002-TWENTY-THIRD-EVENING-H-C-Andersen.txt',\n",
       " 'data/cluster083/c235.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<title>/IN --> IN/IN\\n',\n",
       " 'THE/DT --> the/DT\\n',\n",
       " 'FARMYARD/NNP --> FARMYARD/NNP\\n',\n",
       " 'COCK/NNP --> COCK/NNP\\n',\n",
       " 'AND/CC --> and/CC\\n',\n",
       " 'THE/DT --> the/DT\\n',\n",
       " 'WEATHERCOCK/NNP --> WEATHERCOCK/NNP\\n',\n",
       " './. --> ./.\\n',\n",
       " '</title>/NNP --> NNP/NNP\\n',\n",
       " '<author>/NNP --> NNP/NNP\\n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_list[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes the first, not letmmatized, instance of each token\n",
    "trimmed_story_list = []\n",
    "for sentence in story_list:\n",
    "    for token in sentence:\n",
    "        if \"-->\" in token:\n",
    "            split_token = token.split(\"-->\", 1)\n",
    "            trimmed_story_list.append(split_token[1])\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' IN/IN\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_story_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes \"/n\" from the end of each token\n",
    "cleaned_list = []\n",
    "for item in trimmed_story_list:\n",
    "    new_item = item[:-1]\n",
    "    cleaned_list.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' IN/IN',\n",
       " ' the/DT',\n",
       " ' FARMYARD/NNP',\n",
       " ' COCK/NNP',\n",
       " ' and/CC',\n",
       " ' the/DT',\n",
       " ' WEATHERCOCK/NNP',\n",
       " ' ./.',\n",
       " ' NNP/NNP',\n",
       " ' NNP/NNP']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds only relevant tokens to filtered_list: removes tokens that are not word, as well as words irrelevant to our \n",
    "# study (such as determinants)\n",
    "filtered_list=[]\n",
    "for item in cleaned_list:\n",
    "    if item.startswith((\" .\", \" ,\", \" /\", \" :\", \" ;\", \" '\", \" `\", \" NNP\", \" ?\", \" !\", \" -\")): #numbers? cd\n",
    "        continue\n",
    "    elif item.endswith((\"CC\", \"IN\", \"DT\")):\n",
    "        continue\n",
    "    else:\n",
    "        filtered_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' FARMYARD/NNP',\n",
       " ' COCK/NNP',\n",
       " ' WEATHERCOCK/NNP',\n",
       " ' H./NNP',\n",
       " ' C./NNP',\n",
       " ' Andersen/NNP',\n",
       " ' there/EX',\n",
       " ' be/VBD',\n",
       " ' two/CD',\n",
       " ' cock/NNS']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_list[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move on the explore the data. To do so, we'll take a look at the stories themselves and what we can tell from the data before training any model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
